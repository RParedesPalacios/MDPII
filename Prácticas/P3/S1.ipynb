{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos formativos\n",
    "- Diseñar un experimento de clasificación mediante árbol de decisión\n",
    "- Analizar los resultados obtenidos en un problema de clasificación\n",
    "- Realizar una búsqueda de los mejores parámetros \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "\n",
    "Descargamos el dataset y dibujamos empleando dos características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    " \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,[2,3]]\n",
    "Y = iris.target\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.axis([0.5, 7.5, -0.25, 3])\n",
    "ax.scatter(X[0:49,0], X[0:49,1], color=\"magenta\", marker=\"d\") \n",
    "ax.scatter(X[50:99,0], X[50:99,1], color=\"r\", marker=\"v\") \n",
    "ax.scatter(X[100:149,0], X[100:149,1], color=\"b\", marker=\"*\") \n",
    "ax.set_title(\"Iris\")\n",
    "\n",
    "ax.set_xlabel(\"Longitud de pétalo\")\n",
    "ax.set_ylabel(\"Anchura de pétalo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empleamos un árbol de decisión\n",
    "\n",
    "Vemos las fronteras de decisión del clasificador obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=3, min_samples_split=2, random_state=23)\n",
    "DT.fit(X, Y)\n",
    "\n",
    "\n",
    "y1_min, y1_max = 0.5, 7.5\n",
    "y2_min, y2_max = -0.25, 3\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(y1_min, y1_max, 0.1),np.arange(y2_min, y2_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots()\n",
    "Z = DT.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "axarr.contourf(xx, yy, Z, alpha=0.4)\n",
    "axarr.scatter(X[0:49,0], X[0:49,1], color=\"magenta\",marker=\"d\")\n",
    "axarr.scatter(X[50:99,0], X[50:99,1], color=\"r\",marker=\"v\")\n",
    "axarr.scatter(X[100:149,0], X[100:149,1], color=\"b\",marker=\"*\")\n",
    "axarr.set_title(\"KNN (K=1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el conjunto de datos entre training y test y clasificar\n",
    "\n",
    "Vamos a dividir el conjunto de datos en entrenamiento y test. A continuación emplearemos el entrenamiento para definir un clasificador y el de test para evaluarlo sobre dicho clasificador.\n",
    "\n",
    "Además vamos a emplear ya las 4 variables que hay en Iris.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "## Partición train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=12)\n",
    "\n",
    "\n",
    "## Entrenamiento\n",
    "DT = DecisionTreeClassifier(max_depth=3, min_samples_split=2, random_state=23)\n",
    "DT.fit(X_train, y_train)\n",
    "\n",
    "## Evaluación sobre el test\n",
    "acc=DT.score(X_test,y_test)\n",
    "\n",
    "\n",
    "print(f'Precisión: {acc:.1%}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Cuando tenemos tan pocos datos como es el caso de Iris lo ideal es realizar una validación cruzada para obtener una mejor estimación del error de clasificación. \n",
    "\n",
    "Busca en la documentación de DecisionTreeClassifier cuáles son los principales argumentos y mediante GridSearch con validación cruzada realiza una exploración de los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Implementa un pipeline con PCA y busca los mejores parámetros (PCA y DT) mediante GridSearch y validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación del dataset Digits\n",
    "\n",
    "Emplearemos ahora el dataset DIGITS, imágenes de 8x8 píxeles de los 10 dígitos $[0,9]$. En total hay 1797 imágenes de 8x8 píxeles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()\n",
    "\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"%i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Realizar una validación cruzada para encontrar los mejores parámetros, también implementa un pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

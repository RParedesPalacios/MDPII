{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492bc8de",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h3>Modelos Descriptivos y Predictivos II - Grado en Ciencia de Datos</h3>\n",
    "    <h3>Universitat Politècnica de València</h3>\n",
    "    <h1>Práctica 4: Máquinas de Soporte Vectorial (SVM)</h1>\n",
    "    <h2>Sesión 2</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17baa2da",
   "metadata": {},
   "source": [
    "### Objetivos formativos:\n",
    "\n",
    "- Entender los conceptos fundamentales del clasificador SVM y saber aplicarlo en distintas tareas, tanto sintéticas como reales.\n",
    "- Saber encontrar los hiperparámetros óptimos para una tarea determinada.\n",
    "- Aplicar SVM a tareas tanto binarias como multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17340e96",
   "metadata": {},
   "source": [
    "### Importación de módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e387628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs, make_circles, load_wine, load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d1f26b",
   "metadata": {},
   "source": [
    "### Creación de datasets artificiales\n",
    "\n",
    "En esta práctica usaremos algunos conjuntos de datos creados de manera artificial. A continuación se da el código de distintas funciones para crear estos datasets:\n",
    "- `create_dataset_linear`: genera puntos n-dimensionales en dos grupos (blobs) con centroides en (-1,-1,...,-1) y (1,1,...,1).<br>**Parámetros:**\n",
    "    - `samples`: número de puntos a generar.\n",
    "    - `std`: dispersión (desviación estándar) de los puntos en cada grupo. Puede ser un `float` (todos los grupos tienen la misma dispersión) o un array (permite especificar una dispersión distinta para cada grupo).\n",
    "    - `n_features`: dimensión de los puntos generados.\n",
    "- `create_dataset_moons`: genera puntos 2D en dos grupos con formas de media luna.<br>**Parámetros:**\n",
    "    - `samples`: número de puntos a generar.\n",
    "    - `noise`: ruido de las muestras. A mayor ruido, mayor solapamiento entre las muestras de ambos grupos.\n",
    "\n",
    "- `create_dataset_poly`: genera puntos 2D en dos grupos separados por una frontera poligonal<br>**Parámetros:**\n",
    "    - `coefs`: coeficientes del polígono que define la frontera.\n",
    "    - `samples`: número de puntos a generar.\n",
    "    - `noise`: ruido de las muestras. A mayor ruido, mayor solapamiento entre las muestras de ambos grupos.\n",
    "    - `box`: tamaño del cuadrado en el que se enmarcan los puntos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10aee56",
   "metadata": {},
   "source": [
    "**Funciones generadoras de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab8bab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_linear(samples=300, std=0.5, n_features=2): \n",
    "    # Generar un conjunto de datos linealmente separable\n",
    "    X, y = make_blobs(n_samples=samples, centers=[[-1]*n_features, [1]*n_features] , n_features=n_features, cluster_std=std, random_state=17)\n",
    "    return X, y\n",
    "\n",
    "def create_dataset_moons(samples=300, noise=0.1):\n",
    "    # Generar un conjunto de datos con clases en forma de dos lunas\n",
    "    X, y = make_moons(n_samples=samples, noise=noise, random_state=32)\n",
    "    return X, y\n",
    "\n",
    "def create_dataset_poly(coefs, samples=300, noise=0.1, box=20):\n",
    "    np.random.seed(32)\n",
    "    X = np.random.uniform(-box/2, box/2, (samples, 2))\n",
    "    y = np.zeros(samples)\n",
    "    grade = len(coefs)-1\n",
    "    for i, p in enumerate(X):\n",
    "        px,py = p[0],p[1]\n",
    "        y_poly = sum(coef * (px ** (grade-j)) for j, coef in enumerate(coefs))\n",
    "        y_noisy = y_poly + np.random.uniform(-noise, noise)*box\n",
    "        y[i] = 0 if y_noisy < py else 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daf6ac",
   "metadata": {},
   "source": [
    "### Ejercicio 4. Problemas con más de dos clases\n",
    "\n",
    "Aunque el lasificador SVM está pensado para clasificación binaria, es posible abordar problemas con más de dos clases mediante estrategias como **one-vs-one (OvO)** o **one-vs-rest (OvR)**.\n",
    "\n",
    "- **one-vs-one:** Para un problema de $k$ clases se entrenan $\\frac{k(k-1)}{2}$ clasificadores, cada uno para una pareja de clases.\n",
    "- **one-vs-rest:** Para $k$ clases se entrenan $k$ clasificadores, cada uno para separar una clase del resto.\n",
    "\n",
    "Debe tenerse en cuenta, por tanto, que estas técnicas conllevan un mayor coste computacional debido al mayor número de clasificadores que deben entrenarse.\n",
    "\n",
    "La clase **SVC** de *sklearn* está diseñada para lidiar con este tipo de estrategias. Para estos casos, se puede espeficicar el parámetro `decision_function_shape` con los valores `'ovo'` (valor por defecto, que indica estrategia one-vs-one) o `'ovr'` (estrategia one-vs-rest).\n",
    "\n",
    "Para este ejercicio vamos a crear en primer lugar un dataset artificial con 3 clases y 3 características, tal y como aparece en el código que se da a continuación. Observa que cada clase es un *cluster* de puntos con centroides en [-1,-1,-1], [0,0,0] y [1,1,1]. Los puntos de cada *cluster* tienen una desviación estándar de 0.75 para provocar cierto solapamiento entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982583f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset con 3 clases\n",
    "n_features=3\n",
    "X, y = make_blobs(n_samples=300, centers=[[-1]*n_features, [0]*n_features, [1]*n_features], cluster_std=0.75, random_state=42)\n",
    "\n",
    "# Plotear dataset\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbeeb7b",
   "metadata": {},
   "source": [
    "**Se pide:**\n",
    "- Divide el dataset en conjuntos de entrenamiento y test mediante la función `train_test_split`. Utiliza el 20% de las muestras para test y el 80% restante para entrenamiento.\n",
    "- Emplea un clasificador `SVC` para abordar el problema propuesto mediante la estrategia **OvO**.\n",
    "- Encuentra los hiperparámetros que ofrezcan mejores resultados con el conjunto de entrenamiento. Utiliza para ello `GridSearchCV`.\n",
    "- Muestra los resultados obtenidos con el conjunto de entrenamiento para cada uno de los hiperparámetros analizados. Utiliza para ello la función `show_results_gs` que se da más abajo.\n",
    "- Muestra los resultados obtenidos con el conjunto de test en el mejor modelo. Utiliza para ello la función `classification_report(y_test, y_pred)` del módulo `sklearn.metrics` la cual muestra tanto el *accuracy* como otras métricas (*precision*, *recall*, *f1-score*).\n",
    "\n",
    "Deberías lograr un *accuracy* en el conjunto de test en torno a 0.85."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca59527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUÍ TU SOLUCIÓN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce95aa22",
   "metadata": {},
   "source": [
    "### Ejercicio 5. Problemas con un conjuntos de datos reales: \n",
    "- **Dataset Breast Cancer**\n",
    "- **Dataset Wine**\n",
    "\n",
    "Objetivos: \n",
    "- Trabajar con datasets reales y encontrar el mejor clasificador SVM.\n",
    "- Trabajar con conjuntos de datos balanceados y desbalanceados y obtener resultados con distintas métricas.\n",
    "\n",
    "#### 5.1. Dataset Breast Cancer\n",
    "\n",
    "El dataset *Breast Cancer*  contiene información obtenida de imágenes digitalizadas de biopsias de cáncer de mama. Se utiliza para predecir si un tumor es benigno (clase 1) o maligno (ckase 0) en función de diversas características extraídas de las imágenes como el radio del tumor, el perímetro, el área, ...\n",
    "\n",
    "**Se pide:**\n",
    "\n",
    "1. Con el código que se da más abajo, carga el dataset *breast cancer* y obtén una descripción básica del mismo para ver qué tipo de características contiene. En función de eso decide si necesitas hacer algún preproceso de estos datos (mediante Pipeline) antes de usarlos como entrada de un clasificador.\n",
    "1. A continuación crea conjuntos de entrenamiento (80%) y test (20%) y encuentra el mejor clasificador SVM para este dataset.\n",
    "1. Muestra los resultados obtenidos en el conjunto de entrenamiento con los distintos hiperparámetros.\n",
    "1. Muestra los resultados obtenidos en el conjunto de entrenamiento con los distintos hiperparámetros.\n",
    "1. Muestra el resultado obtenido (precision, recall, f1-score, accuracy) en el conjunto de test con el mejor clasificador. Usa para ello la función `classification_report` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset breast cancer y mostrar una descripción básica del mismo\n",
    "data = load_breast_cancer()\n",
    "X = data.data  \n",
    "y = data.target\n",
    "feature_names = data.feature_names\n",
    "\n",
    "# Crear un DataFrame\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "# Distribución de la variable objetivo\n",
    "print('Balanceo de clases')\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69cc36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUÍ TU SOLUCIÓN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f3387",
   "metadata": {},
   "source": [
    "#### 5.2. Dataset Wine\n",
    "\n",
    "El dataset *Wine* contiene variables relacionadas con el análisis químico de vinos italianos provenientes de tres variedades diferentes. Su objetivo es clasificar cada muestra de vino en una de esas tres variedades. Se trata, por tanto, de un problema multiclase.\n",
    "\n",
    "El dataset contiene 178 observaciones y 13 características como son la cantidad de alcohol, cenizas, magnesio, fenoles, ...\n",
    "\n",
    "**Se pide** hacer un análisis similar al realizado con el dataset de *breast cancer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bf8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESCRIBE AQUÍ TU SOLUCIÓN \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDPII",
   "language": "python",
   "name": "mdp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
